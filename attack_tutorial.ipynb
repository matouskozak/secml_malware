{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SecML Malware Tutorial\n",
    "\n",
    "In this tutorial, you will learn how to use this plugin to test the already implemented attacks against a PyTorch network of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import magic\n",
    "import numpy as np\n",
    "from secml.array import CArray\n",
    "\n",
    "from secml_malware.models.malconv import MalConv\n",
    "from secml_malware.models.c_classifier_end2end_malware import CClassifierEnd2EndMalware, End2EndModel\n",
    "\n",
    "net = MalConv()\n",
    "net = CClassifierEnd2EndMalware(net)\n",
    "net.load_pretrained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we have created the network (MalConv) and it has been passed wrapped with a *CClassifierEnd2EndMalware* model class.\n",
    "This object generalizes PyTorch end-to-end ML models.\n",
    "Since MalConv is already coded inside the plugin, the weights are also stored, and they can be retrieved with the *load_pretrained_model* method.\n",
    "\n",
    "If you wish to use diffierent weights, pass the path to the PyTorch *pth* file to that method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secml_malware.attack.whitebox.c_header_evasion import CHeaderEvasion\n",
    "\n",
    "partial_dos = CHeaderEvasion(net, random_init=False, iterations=50, optimize_all_dos=False, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how an attack is created, no further action is needed.\n",
    "The `random_init` parameter specifies if the bytes should be assigned with random values before beginning the optimization process, `iterations` sets the number of steps of the attack, `optimize_all_dos` sets if all the DOS header should be perturbed, or just the first 58 bytes, while `threshold` is the detection threshold used as a stopping condition.\n",
    "\n",
    "If you want to see how much the network is deteriorated by the attack, set this parameter to 0, or it will stop as soon as the confidence decreases below such value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Added 0afe9ffafbdf80bfddd05114a9847c15609aa9211dd8cd69c49b2bf3eef6cd98 with confidence 0.999637246131897\n",
      "> Added 0a82e375f241b336ba7b8291ac11e1a473f6f9901a63947545cd408842de6d04 with confidence 0.9999984502792358\n",
      "> Added 0a3eda8ad3782d74184ee6135bd2f92abdc6e7eaab33fc772d2544b6763dc9ce with confidence 0.9999998807907104\n",
      "> Added 0a163977c100b9e91ab0a50b5829a0123de7cb7cfd1bf12e8b8f7cc305e6de26 with confidence 1.0\n",
      "> Added 0c4a4f5b31be5734f75b5180991ff505d8473ddbf7d44a483ae9192485f470fc with confidence 0.9999771118164062\n",
      "> Added 0a38c8606f4314dfaeb46f85013e80e7c6ebca2d0f76e3c20a9f0b0f5dcec0af with confidence 1.0\n",
      "> Added 0c7f8ee337986ff2ec23e5d5bd388413ed6f9fe1042fa2b49f849b5046206b0b with confidence 1.0\n",
      "> Added 0b934e15db3b41777881878929bd93c04991ca780c705c6e7600aec45a674a2f with confidence 1.0\n",
      "> Added 0c12e3093a4031d139184c2da5bf4691676404085fbe7ac4407ba4460ed2f80d with confidence 0.9999653100967407\n",
      "> Added 0a31e5171828c68fd1510c1d78b434f41eb74049e9c63be380f1eab40adf617a with confidence 0.9999998807907104\n",
      "> Added 0bb70afbf093733cd0f6725f67b2c9866c491f6ba9da46bf1d9f7516c76b4766 with confidence 0.9999998807907104\n",
      "> Added 0a7db363cd562cc005c64695918f1de5faf6f2dcdf48e96184c6c3d41105fdc4 with confidence 0.8777130246162415\n",
      "> Added 0ab2a0209655b4a8e71680f3cd9edc375ff3baaeced5c60a1b00372009b0fa1b with confidence 0.9923455119132996\n",
      "> Added 0c1aed2551d12ad708fe3213059b83f4457ebad7334cf0a4899fa81bed7e3b5f with confidence 1.0\n"
     ]
    }
   ],
   "source": [
    "folder = \"secml_malware/data/malware_samples/test_folder\"\n",
    "#folder = \"/home/matous/Documents/CVUT_FIT/DP/diploma-thesis/src/AMG/gym_malware/envs/utils/samples/val/\"\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "file_names = []\n",
    "skip_files = []\n",
    "\n",
    "for i, f in enumerate(os.listdir(folder)):\n",
    "    path = os.path.join(folder, f)\n",
    "    #if 'petya' not in path:\n",
    "    #    continue\n",
    "    if \"PE32\" not in magic.from_file(path):\n",
    "        continue\n",
    "    #print(path)\n",
    "\n",
    "    with open(path, \"rb\") as file_handle:\n",
    "        code = file_handle.read()\n",
    "        \n",
    "    x = End2EndModel.bytes_to_numpy(code, net.get_input_max_length(), 256, False)\n",
    "    \n",
    "    _, confidence = net.predict(CArray(x), True) # Target Classifier (MalConv)\n",
    "    \n",
    "    #print(confidence[0, 1].item(), path)\n",
    "    if confidence[0, 1].item() < 0.5: # Correctly classified -> skip files\n",
    "        skip_files.append(path)\n",
    "        continue\n",
    "\n",
    "    print(f\"> Added {f} with confidence {confidence[0,1].item()}\")\n",
    "    X.append(x)\n",
    "    conf = confidence[1][0].item()\n",
    "    y.append([1 - conf, conf])\n",
    "    file_names.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a simple dataset from the `malware_samples/test_folder` that you have filled with malware to test the attacks.\n",
    "We discard all the samples that are not seen by the network.\n",
    "The `CArray` class is the base object you will handle when dealing with vectors in this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files to modifie: 14\n",
      "Number of skipped files: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of files to modifie:\", len(file_names))\n",
    "print(\"Number of skipped files:\", len(skip_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save skip_files\n",
    "for path in skip_files:\n",
    "    os.system(f\"cp {path} {os.path.join('secml_malware/output', f'{os.path.basename(path)}_skip')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.999637246131897, 0.3429279327392578]\n",
      "0.3429279327392578\n",
      "[0.9999984502792358, 0.9635927677154541, 0.4626123607158661]\n",
      "0.4626123607158661\n",
      "[0.9999998807907104, 0.9918041229248047, 0.025469491258263588]\n",
      "0.025469491258263588\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n",
      "[0.9999771118164062, 0.13744504749774933]\n",
      "0.13744504749774933\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n",
      "[0.9999653100967407, 0.09325119853019714]\n",
      "0.09325119853019714\n",
      "[0.9999998807907104, 0.4184616506099701]\n",
      "0.4184616506099701\n",
      "[0.9999998807907104, 0.999778687953949, 0.9978123903274536, 0.9967156648635864, 0.9966655373573303, 0.9961584210395813, 0.9952580332756042, 0.9960427284240723, 0.996610701084137, 0.9963118433952332, 0.9956299066543579, 0.9962288737297058, 0.9965720176696777, 0.996342122554779, 0.9957406520843506, 0.9961073994636536, 0.9965225458145142, 0.9964268803596497, 0.9956920742988586, 0.9961393475532532, 0.996610701084137, 0.9963118433952332, 0.9956299066543579, 0.9962288737297058, 0.9965720176696777, 0.996342122554779, 0.9957406520843506, 0.9961073994636536, 0.9965225458145142, 0.9964268803596497, 0.9956920742988586, 0.9961393475532532, 0.996610701084137, 0.9963118433952332, 0.9956299066543579, 0.9962288737297058, 0.9965720176696777, 0.996342122554779, 0.9957406520843506, 0.9961073994636536, 0.9965225458145142, 0.9964268803596497, 0.9956920742988586, 0.9961393475532532, 0.996610701084137, 0.9963118433952332, 0.9956299066543579, 0.9962288737297058, 0.9965720176696777, 0.996342122554779, 0.9957406520843506]\n",
      "0.9957406520843506\n",
      "[0.8777130246162415, 4.122143582208082e-05]\n",
      "4.122143582208082e-05\n",
      "[0.9923455119132996, 0.0002251774858450517]\n",
      "0.0002251774858450517\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Run attacks and save files\n",
    "for sample, label, path in zip(X, y, file_names):\n",
    "    y_pred, adv_score, adv_ds, f_obj = partial_dos.run(CArray(sample), CArray(label[1]))\n",
    "    print(partial_dos.confidences_)\n",
    "    print(f_obj)\n",
    "    \n",
    "    tag = \"\"\n",
    "    if f_obj < 0.5:\n",
    "        tag = \"evasive\"\n",
    "    else:\n",
    "        tag = \"fail\"\n",
    "    \n",
    "    adv_x = adv_ds.X[0,:]\n",
    "    real_adv_x = partial_dos.create_real_sample_from_adv(path, adv_x)\n",
    "    \n",
    "    with open( os.path.join(\"secml_malware/output\", f\"{os.path.basename(path)}_{tag}\"), 'wb') as outfile:\n",
    "        outfile.write( real_adv_x )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the `adv_ds` object, you can find the adversarial example computed by the attack.\n",
    "You can reconstruct the functioning example by using a specific function inside the plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2679296\n",
      "0.3429279327392578\n"
     ]
    }
   ],
   "source": [
    "adv_x = adv_ds.X[0,:]\n",
    "real_adv_x = partial_dos.create_real_sample_from_adv(file_names[0], adv_x, new_file_path=os.path.join(\"secml_malware/output\", os.path.basename(file_names[0])))\n",
    "print(len(real_adv_x))\n",
    "real_x = End2EndModel.bytes_to_numpy(real_adv_x, net.get_input_max_length(), 256, False)\n",
    "_, confidence = net.predict(CArray(real_x), True)\n",
    "print(confidence[0,1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and you're done!\n",
    "If you want to create a real sample (stored on disk), just have a look at the `create_real_sample_from_adv` of each attack. It accepts a third string argument that will be used as a destination file path for storing the adversarial example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bonus: more attacks!\n",
    "We used one attack, which is the Partial DOS one. But what if we want to use others?\n",
    "Easy peasy task! Just open the [source code](https://github.com/pralab/secml_malware/tree/master/secml_malware/attack/whitebox) or the [documentation](https://secml-malware.readthedocs.io/en/docs/source/secml_malware.attack.whitebox.html) of the other white box attacks, and instantiate the one you like!\n",
    "Let's use the [FGSM attack](https://arxiv.org/abs/1802.04528), for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't read the padding content of section 'UPX1'\n",
      "Data of section section '.rsrc' is too large (0xffea6000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.999637246131897, 0.999637246131897, 0.999637246131897, 0.999637246131897, 0.999637246131897, 0.999637246131897]\n",
      "0.999637246131897\n",
      "[0.9999984502792358, 1.0237579848629806e-21]\n",
      "0.0004633114149328321\n",
      "[0.9999998807907104, 6.979263212124166e-23]\n",
      "0.004021089524030685\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't read the padding content of section '        '\n",
      "Data of section section '.idata' is too large (0xffe6a000)\n",
      "Data of section section '.rsrc' is too large (0xffe69000)\n",
      "Data of section section '.themida' is too large (0xffe67000)\n",
      "Data of section section '.boot' is too large (0xffe67000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999771118164062, 0.9999771118164062, 0.9999771118164062, 0.9999771118164062, 0.9999771118164062, 0.9999771118164062]\n",
      "0.9999771118164062\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Address of new exe header is corrupted\n",
      "Fail to parse the DOS Stub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n",
      "[0.9999653100967407, 0.9976542592048645, 0.0]\n",
      "5.942947112203001e-08\n",
      "[0.9999998807907104, 0.0]\n",
      "2.650436363182962e-05\n",
      "[0.9999998807907104, 0.0]\n",
      "2.334816144866636e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't read the padding content of section 'UPX1'\n",
      "Data of section section 'UPX2' is too large (0xffffbe01)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8777130246162415, 0.0]\n",
      "2.619011318927278e-08\n",
      "[0.9923455119132996, 0.39388877153396606]\n",
      "0.9922105073928833\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from secml_malware.attack.whitebox import CKreukEvasion\n",
    "\n",
    "fgsm = CKreukEvasion(net, how_many_padding_bytes=2048, epsilon=1.0, iterations=5)\n",
    "for i, (sample, label) in enumerate(zip(X, y)):\n",
    "    y_pred, adv_score, adv_ds, f_obj = fgsm.run(CArray(sample), CArray(label[1]))\n",
    "    print(fgsm.confidences_)\n",
    "    print(f_obj)\n",
    "    #with open(file_names[i], 'rb') as f:\n",
    "    #    print('Original length: ', len(f.read()))\n",
    "    #print('Adversarial sample length: ', len(real_adv_x))\n",
    "    \n",
    "    tag = \"\"\n",
    "    if f_obj < 0.5:\n",
    "        tag = \"evasive\"\n",
    "    else:\n",
    "        tag = \"fail\"\n",
    "    \n",
    "    adv_x = adv_ds.X[0,:]\n",
    "    real_adv_x = fgsm.create_real_sample_from_adv(file_names[i], adv_x)\n",
    "    \n",
    "    with open( os.path.join(\"secml_malware/output\", f\"{os.path.basename(file_names[i])}_{tag}\"), 'wb') as outfile:\n",
    "        outfile.write( real_adv_x )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "... and you're done! Remember that this particular attack might take a while, depending on how many bytes the algorithm is tasked to edit (and also for the number of iterations).\n",
    "In the meantime, **happy coding with SecML Malware!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
